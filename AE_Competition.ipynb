{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualize(headers, dataset_f, dataset_l):\n",
    "    for i in range(len(headers)):\n",
    "        plt.figure(num=i, figsize=(18, 10), dpi=80)\n",
    "        plt.title(headers[i])\n",
    "        plt.scatter(range(len(dataset_f.iloc[:, 0])), dataset_f.iloc[:, i], c = dataset_l, s=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For training data\n",
    "def train_preprocess(dataset):\n",
    "    dataset = dataset.drop(['DATETIME'], axis=1)\n",
    "\n",
    "    dataset_f = dataset.iloc[:, 0:-1]\n",
    "    dataset_l = dataset.iloc[:, -1]\n",
    "\n",
    "    headers = list(dataset_f)\n",
    "    \n",
    "    return headers, dataset_f, dataset_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For testing data\n",
    "def test_preprocess(dataset):\n",
    "    dataset = dataset.drop(['DATETIME'], axis=1)\n",
    "    headers = list(dataset)\n",
    "    \n",
    "    return headers, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate random window size\n",
    "def generate_win_size(data_size):\n",
    "    windows = []\n",
    "    for i in range(data_size):\n",
    "        window_size = random.randint(125, 133)\n",
    "        if sum(windows) + window_size <data_size:\n",
    "            windows.append(window_size)\n",
    "        else:\n",
    "            windows.append(data_size - sum(windows))\n",
    "            return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate index for windows\n",
    "def generate_index(windows):\n",
    "    indexs = [0]\n",
    "    for i in range(1, len(windows)):\n",
    "        indexs.append(indexs[i-1] + windows[i-1])\n",
    "    return indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating p-values for each window\n",
    "def calculate_p(headers, windows, indexs, train1_f, test):\n",
    "    all_pvals = []\n",
    "    all_sorted_index = []\n",
    "    for j in range(len(headers)):\n",
    "        pvals = []\n",
    "        for i in range(0, len(windows) - 1):\n",
    "            ks_status, pval = ks_2samp(train1_f.iloc[:, j], test.iloc[indexs[i]:indexs[i+1], j])\n",
    "            pvals.append(pval)\n",
    "            \n",
    "        sorted_index = sorted(range(len(pvals)), key=lambda k: pvals[k])\n",
    "        all_sorted_index.append(sorted_index)\n",
    "        pvals.sort()\n",
    "        all_pvals.append(pvals)\n",
    "        \n",
    "    return all_pvals, all_sorted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify attack index\n",
    "def identify_attack(all_pvals, all_sorted_index, numeric_threshold, binary_threshold):\n",
    "    attack = []\n",
    "    \n",
    "    ## Identify attack for numeric features\n",
    "    for i in range(0, 31):\n",
    "        for j in range(len(all_pvals[0])):\n",
    "            if all_pvals[i][j] < 10**numeric_threshold:\n",
    "                attack.append(all_sorted_index[i][j])\n",
    "                \n",
    "    ## Identify attack for binary features\n",
    "    for i in range(31, 43):\n",
    "        for j in range(len(all_pvals[0])):\n",
    "            if all_pvals[i][j] < 10**binary_threshold:\n",
    "                attack.append(all_sorted_index[i][j])\n",
    "                \n",
    "    return list(set(attack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate False padding\n",
    "def generate_false(size):\n",
    "    padding_False = []\n",
    "    for i in range(size):\n",
    "        padding_False.append([False])\n",
    "    padding_False = np.array(padding_False)   \n",
    "    return padding_False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate True padding\n",
    "def generate_true(size):\n",
    "    padding_True = []\n",
    "    for i in range(size):\n",
    "        padding_True.append([True])\n",
    "    padding_True = np.array(padding_True)   \n",
    "    return padding_True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate one batch result\n",
    "def one_batch(train1_f, test, headers, numeric_threshold, binary_threshold):\n",
    "    ## Size of test set\n",
    "    test_size = test.shape[0]\n",
    "    \n",
    "    ## Generating windows and indexs\n",
    "    windows = generate_win_size(test_size)\n",
    "    indexs = generate_index(windows)\n",
    "    \n",
    "    ## Calculating p values for each window\n",
    "    all_pvals, all_sorted_index = calculate_p(headers, windows, indexs, train1_f, test)\n",
    "    \n",
    "    ## Identify Attack\n",
    "    final_attack = identify_attack(all_pvals, all_sorted_index, numeric_threshold, binary_threshold)\n",
    "    \n",
    "    ## Generating result for one batch\n",
    "    result = []\n",
    "    for i in range(len(windows)):\n",
    "        result.append(generate_false(windows[i]))\n",
    "        \n",
    "    ## Change attack labels\n",
    "    for i in range(len(final_attack)):\n",
    "        result[final_attack[i]] = generate_true(windows[final_attack[i]])\n",
    "        \n",
    "    batch_result = np.vstack(result)\n",
    "    return batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run n batches to optimize result\n",
    "def multiple_batches(batches, train1_f, test, headers, numeric_threshold, binary_threshold):\n",
    "    batch_list = []\n",
    "    for i in range(batches):\n",
    "        print('Start Batch No.', i+1)\n",
    "        batch_result = one_batch(train1_f, test, headers, numeric_threshold, binary_threshold)\n",
    "        batch_list.append(batch_result)\n",
    "        print('Finish Batch No.', i+1)\n",
    "        \n",
    "    add_on = batch_list[0]\n",
    "    for i in range(1, len(batch_list)):\n",
    "        add_on += batch_list[i]\n",
    "        \n",
    "    final_result = add_on >= int(1)\n",
    "    return add_on, final_result        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Batch No. 1\n",
      "Finish Batch No. 1\n",
      "Start Batch No. 2\n",
      "Finish Batch No. 2\n",
      "Start Batch No. 3\n",
      "Finish Batch No. 3\n",
      "Start Batch No. 4\n",
      "Finish Batch No. 4\n",
      "Start Batch No. 5\n",
      "Finish Batch No. 5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ## Load Training data\n",
    "    train1 = pd.read_csv('training/train_dataset01.csv')*1\n",
    "    train2 = pd.read_csv('training/train_dataset02.csv')*1\n",
    "\n",
    "    ## Load Testing data\n",
    "    test = pd.read_csv('test_dataset.csv')*1\n",
    "    \n",
    "    ## Pre-Process\n",
    "    headers, train1_f, train1_l = train_preprocess(train1)\n",
    "    headers, train2_f, train2_l = train_preprocess(train2)\n",
    "    \n",
    "    headers, test = test_preprocess(test)\n",
    "    \n",
    "    ## Visulize the data\n",
    "#     data_visualize(headers, train1_f, train1_l)\n",
    "#     data_visualize(headers, train2_f, train2_l)\n",
    "    \n",
    "    ## Prediction\n",
    "#     prediction = generate_output(train1_f, test, 129, headers, -43, -12)\n",
    "    add_on, prediction = multiple_batches(5, train1_f, test, headers, -43, -12)\n",
    "    \n",
    "    ## Save to CSV file\n",
    "    csv_df = pd.DataFrame(prediction)\n",
    "    csv_df.to_csv('yourname.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
